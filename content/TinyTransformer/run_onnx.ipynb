{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import onnxruntime\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 创建模型配置文件\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    block_size: int = 1024\n",
    "    vocab_size: int = 50304\n",
    "    n_layer: int = 4\n",
    "    n_head: int = 4\n",
    "    n_embd: int = 768\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True\n",
    "\n",
    "model_config = TransformerConfig(vocab_size=10, block_size=12, n_layer=2, n_head=4, n_embd=16, dropout=0.0, bias=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\n",
      "number of parameters: 0.02M\n",
      "ONNX Output Tensor Shape: torch.Size([1, 1, 10])\n",
      "ONNX Output Tensor: tensor([[[-0.0452,  0.0436, -0.0248,  0.1356,  0.0727, -0.0507, -0.1029,\n",
      "          -0.1260,  0.0055,  0.0508]]])\n",
      "idx torch.Size([1, 12])\n",
      "tok_emb torch.Size([1, 12, 16])\n",
      "x after wpe: torch.Size([1, 12, 16])\n",
      "enc_out: torch.Size([1, 12, 16])\n",
      "x after decoder: torch.Size([1, 12, 16])\n",
      "PyTorch Output Tensor Shape: torch.Size([1, 1, 10])\n",
      "PyTorch Output Tensor: tensor([[[-0.0924, -0.0464,  0.1344, -0.0711,  0.1091, -0.0670,  0.1169,\n",
      "          -0.1366,  0.0530,  0.0289]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建模型\n",
    "\n",
    "from tiny_transformer import Transformer\n",
    "\n",
    "model = Transformer(model_config)\n",
    "\n",
    "\n",
    "# ONNX 模型路径\n",
    "onnx_model_path = \"transformer.onnx\"\n",
    "\n",
    "# 创建 ONNX Runtime 会话\n",
    "ort_session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "\n",
    "# 准备输入数据 (必须是 numpy 数组)\n",
    "# 确保输入形状与导出时使用的 dummy_input 匹配，并且数据类型正确\n",
    "# 例如: (batch_size, sequence_length)\n",
    "batch_size = 1\n",
    "sequence_length = model_config.block_size  # 使用 block_size\n",
    "input_data = torch.randint(1, 10, (batch_size, sequence_length)).numpy().astype(np.int64)\n",
    "\n",
    "# 运行 ONNX 推理\n",
    "ort_inputs = {'input': input_data}  # 输入名称必须与导出时指定的一致\n",
    "ort_outputs = ort_session.run(None, ort_inputs) # None 表示获取所有输出\n",
    "\n",
    "# ort_outputs 是一个列表，包含所有输出的结果\n",
    "#  根据模型定义，假设我们只有一个输出\n",
    "onnx_output = ort_outputs[0]\n",
    "\n",
    "# 转换回 PyTorch Tensor (如果需要)\n",
    "onnx_output_tensor = torch.from_numpy(onnx_output)\n",
    "\n",
    "# 打印结果\n",
    "print(\"ONNX Output Tensor Shape:\", onnx_output_tensor.shape)\n",
    "print(\"ONNX Output Tensor:\", onnx_output_tensor)\n",
    "\n",
    "# 可选: 与 PyTorch 模型的结果进行比较，以验证 ONNX 转换的正确性\n",
    "# 注意: 需要使用相同的输入数据，并且确保 PyTorch 模型处于 eval 模式\n",
    "model.eval()\n",
    "torch_input = torch.from_numpy(input_data)\n",
    "with torch.no_grad():\n",
    "    torch_output, _ = model(torch_input)\n",
    "\n",
    "print(\"PyTorch Output Tensor Shape:\", torch_output.shape)\n",
    "print(\"PyTorch Output Tensor:\", torch_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max difference between PyTorch and ONNX outputs: 0.21988385915756226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Compare outputs\n",
    "if torch_output.shape == onnx_output_tensor.shape:\n",
    "    diff = torch.abs(torch_output - onnx_output_tensor)\n",
    "    max_diff = torch.max(diff)\n",
    "    print(\"Max difference between PyTorch and ONNX outputs:\", max_diff.item())\n",
    "else:\n",
    "    print(\"PyTorch and ONNX outputs have different shapes, cannot compare directly.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
